{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55e82c21-13f8-4b9e-8dbb-a0d2697b38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from utils.jet_dataset import JetDataset\n",
    "from wnae import WNAE\n",
    "from model_config.model_registry import MODEL_REGISTRY\n",
    "import os, random\n",
    "from utils.plotting_helpers import ensure_dir, plot_epoch_1d, plot_epoch_2d\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a743829b-57f4-45fb-a07a-e707382a7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"feat4_encoder32_deep_qcd\"\n",
    "model_config = MODEL_REGISTRY[MODEL_NAME]\n",
    "\n",
    "DATA_PATH = json.load(open(\"data/dataset_config_small.json\"))[model_config[\"process\"]][\"path\"]\n",
    "INPUT_DIM = model_config[\"input_dim\"]\n",
    "SAVEDIR = model_config[\"savedir\"]+\"_sinkhorn\"\n",
    "CHECKPOINT_PATH = f\"{SAVEDIR}/wnae_checkpoint_{INPUT_DIM}.pth\"\n",
    "PLOT_DIR = f\"{SAVEDIR}/plots/\"\n",
    "BATCH_SIZE = 4098\n",
    "NUM_SAMPLES = 2 ** 16\n",
    "LEARNING_RATE = 1e-3\n",
    "N_EPOCHS = 100\n",
    "\n",
    "#For plotting\n",
    "PLOT_DISTRIBUTIONS = True\n",
    "PLOT_EPOCHS  = [10,100,200]  # Final epoch is always added automatically\n",
    "BINS         = np.linspace(-5.0, 5.0, 101)\n",
    "N_1D_SAMPLES = 4   # how many random features to plot for non-final epochs\n",
    "N_2D_SAMPLES = 4    # how many 2D scatter plots to print\n",
    "RNG_SEED     = 0\n",
    "\n",
    "WNAE_PARAMS = {\n",
    "    \"sampling\": \"pcd\",\n",
    "    \"n_steps\":20,\n",
    "    \"noise\":0.05,\n",
    "    \"step_size\":None,\n",
    "    \"temperature\": 1.0,\n",
    "    \"bounds\": (-4.,4.),\n",
    "    \"mh\": False,\n",
    "    \"initial_distribution\": \"gaussian\",\n",
    "    \"replay\": True,\n",
    "    \"replay_ratio\": 0.95,\n",
    "    \"distance\":\"sinkhorn\"\n",
    "}\n",
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07f7dacd-9d3c-4d16-866c-2de57bad75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_training(model, optimizer, loss_function, n_epochs, training_loader, validation_loader,checkpoint_path=None,save_every=20):\n",
    "\n",
    "    start_epoch = 0\n",
    "    training_losses, validation_losses = [], []\n",
    "    batch_pos_energies, batch_neg_energies = [], []\n",
    "\n",
    "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "        ckpt = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "        start_epoch = ckpt.get(\"epoch\", 0)\n",
    "        training_losses = ckpt.get(\"training_losses\", [])\n",
    "        validation_losses = ckpt.get(\"validation_losses\", [])\n",
    "        batch_pos_energies = ckpt.get(\"batch_pos_energies\", [])\n",
    "        batch_neg_energies = ckpt.get(\"batch_neg_energies\", [])\n",
    "        if \"buffer\" in ckpt:\n",
    "            print(\"Loading replay buffer from checkpoint\")\n",
    "            if model.buffer.max_samples!=len(ckpt[\"buffer\"]):\n",
    "                print(f'WARNING: stored buffer len ({len(ckpt[\"buffer\"])}) different from declared buffer size {model.buffer.max_samples}')\n",
    "                model.buffer.buffer = ckpt[\"buffer\"][:model.buffer.max_samples]\n",
    "            else:\n",
    "                model.buffer.buffer = ckpt[\"buffer\"]\n",
    "\n",
    "    global PLOT_EPOCHS\n",
    "    PLOT_EPOCHS = sorted(set(PLOT_EPOCHS + [start_epoch + n_epochs]))#Add the last epoch to the list for plotting\n",
    "    for i_epoch in range(start_epoch, start_epoch + n_epochs):\n",
    "        model.train()\n",
    "        training_loss = 0\n",
    "        n_batches = 0\n",
    "        epoch_pos_energy = 0\n",
    "        epoch_neg_energy = 0\n",
    "\n",
    "        bar_format = f\"Epoch {i_epoch+1}/{start_epoch + n_epochs}: \" \\\n",
    "                     + \"{l_bar}{bar:10}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\"\n",
    "\n",
    "        for batch in tqdm(training_loader, bar_format=bar_format):\n",
    "            x = batch[0].to(DEVICE, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if loss_function == \"wnae\":\n",
    "                loss, train_dict = model.train_step(x)\n",
    "            elif loss_function == \"nae\":\n",
    "                loss, train_dict = model.train_step_nae(x)\n",
    "            elif loss_function == \"ae\":\n",
    "                loss, train_dict = model.train_step_ae(x, run_mcmc=True, mcmc_replay=True)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pos_e = train_dict.get(\"positive_energy\", None)\n",
    "            neg_e = train_dict.get(\"negative_energy\", None)\n",
    "            batch_pos_energies.append(pos_e)\n",
    "            batch_neg_energies.append(neg_e)\n",
    "            epoch_pos_energy = epoch_pos_energy + pos_e\n",
    "            epoch_neg_energy = epoch_neg_energy + neg_e\n",
    "\n",
    "            #print(f\"E+: {train_dict['positive_energy']:.2f}, E-: {train_dict['negative_energy']:.2f}\")\n",
    "\n",
    "            training_loss += train_dict[\"loss\"]\n",
    "            n_batches += 1\n",
    "\n",
    "        avg_pos_energy = epoch_pos_energy / n_batches\n",
    "        avg_neg_energy = epoch_neg_energy / n_batches\n",
    "        training_losses.append(training_loss / n_batches)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        validation_loss = 0\n",
    "        n_batches = 0\n",
    "        #with torch.no_grad():\n",
    "        for batch in validation_loader:\n",
    "            x = batch[0].to(DEVICE, non_blocking=True)\n",
    "    \n",
    "            if loss_function == \"wnae\":\n",
    "                val_dict = model.validation_step(x)\n",
    "            elif loss_function == \"nae\":\n",
    "                val_dict = model.validation_step_nae(x)\n",
    "            elif loss_function == \"ae\":\n",
    "                val_dict = model.validation_step_ae(x, run_mcmc=True)\n",
    "            validation_loss += val_dict[\"loss\"]\n",
    "    \n",
    "            if(n_batches==0 and PLOT_DISTRIBUTIONS==True and (i_epoch+1 in PLOT_EPOCHS)):\n",
    "                #Plotting features, positive and negative samples, only for first batch\n",
    "                mcmc = val_dict[\"mcmc_data\"][\"samples\"][-1].detach().cpu().numpy()\n",
    "                data = x.detach().cpu().numpy()\n",
    "                ep_dir = ensure_dir(os.path.join(PLOT_DIR, f\"epoch_{i_epoch+1}\"))\n",
    "    \n",
    "                nfeat = data.shape[1]\n",
    "                if ((i_epoch +1) == (start_epoch + n_epochs)):\n",
    "                    features = range(nfeat)  #plot all features at final epoch\n",
    "                else:\n",
    "                    features = random.Random(RNG_SEED).sample(range(nfeat), N_1D_SAMPLES)\n",
    "                \n",
    "                pairs = random.Random(RNG_SEED).sample(list(itertools.combinations(range(nfeat), 2)),N_2D_SAMPLES)#N_2D_SAMPLES pairs of features to plot\n",
    "                # 1D fixed-binning histograms\n",
    "                plot_epoch_1d(data, mcmc, ep_dir, i_epoch+1, features, BINS)\n",
    "                # a couple of 2D scatters for shape sanity\n",
    "                plot_epoch_2d(data, mcmc, ep_dir, i_epoch+1, pairs)\n",
    "            \n",
    "            n_batches += 1\n",
    "\n",
    "        validation_losses.append(validation_loss / n_batches)\n",
    "\n",
    "        print(f\"Epoch {i_epoch+1}/{start_epoch + n_epochs} | \"\n",
    "      f\"Train Loss: {training_losses[-1]:.4f} | \"\n",
    "      f\"Val Loss: {validation_losses[-1]:.4f} | \"\n",
    "      f\"Avg E+: {avg_pos_energy:.2f} | Avg E-: {avg_neg_energy:.2f}\")\n",
    "\n",
    "        save_epoch = i_epoch%save_every==0 or (start_epoch + n_epochs -1 == i_epoch)\n",
    "        if checkpoint_path and save_epoch:\n",
    "            torch.save({\n",
    "                \"epoch\": i_epoch + 1,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"training_losses\": training_losses,\n",
    "                \"validation_losses\": validation_losses,\n",
    "                \"batch_pos_energies\": batch_pos_energies,\n",
    "                \"batch_neg_energies\": batch_neg_energies,\n",
    "                \"buffer\": model.buffer.buffer\n",
    "            }, checkpoint_path)\n",
    "\n",
    "    return training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4168a174-52b6-4166-bd76-b2fd057ec05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_losses(training_losses, validation_losses, save_dir):\n",
    "    epochs = list(range(len(training_losses)))\n",
    "    ensure_dir(save_dir)\n",
    "    save_path = os.path.join(save_dir, \"training_loss_plot.png\")\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, training_losses, label=\"Training\", color=\"red\", linewidth=2)\n",
    "    plt.plot(epochs, validation_losses, label=\"Validation\", color=\"blue\", linestyle=\"dashed\", linewidth=2)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54e6025a-12a6-4332-9c8b-a17f31db9291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dataset = JetDataset(DATA_PATH)\n",
    "    ensure_dir(SAVEDIR)\n",
    "\n",
    "    # Split\n",
    "    indices = np.arange(len(dataset))\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(0.8 * len(indices))\n",
    "    train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "    train_dataset = JetDataset(DATA_PATH, indices=train_idx, input_dim=INPUT_DIM)\n",
    "    val_dataset = JetDataset(DATA_PATH, indices=val_idx, input_dim=INPUT_DIM)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=RandomSampler(train_dataset, replacement=True, num_samples=NUM_SAMPLES),pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=RandomSampler(val_dataset, replacement=True, num_samples=NUM_SAMPLES),pin_memory=True)\n",
    "\n",
    "    model = WNAE(\n",
    "        encoder=model_config[\"encoder\"](),\n",
    "        decoder=model_config[\"decoder\"](),\n",
    "        **WNAE_PARAMS\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    training_losses, validation_losses = run_training(model=model,optimizer=optimizer,loss_function=\"wnae\",n_epochs=N_EPOCHS,training_loader=train_loader,validation_loader=val_loader,checkpoint_path=CHECKPOINT_PATH)\n",
    "\n",
    "    plot_losses(training_losses, validation_losses, PLOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a10b93-269d-4cca-9a7d-b8995141f302",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 16/16 [00:16<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 0.1087 | Val Loss: 0.1261 | Avg E+: 1.02 | Avg E-: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 | Train Loss: 0.1522 | Val Loss: 0.1547 | Avg E+: 1.02 | Avg E-: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 | Train Loss: 0.1399 | Val Loss: 0.1280 | Avg E+: 1.01 | Avg E-: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 | Train Loss: 0.1380 | Val Loss: 0.1437 | Avg E+: 1.03 | Avg E-: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 | Train Loss: 0.1520 | Val Loss: 0.1475 | Avg E+: 1.81 | Avg E-: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 | Train Loss: 0.1644 | Val Loss: 0.1599 | Avg E+: 2.33 | Avg E-: 2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 | Train Loss: 0.1670 | Val Loss: 0.1585 | Avg E+: 1.52 | Avg E-: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 | Train Loss: 0.1588 | Val Loss: 0.1512 | Avg E+: 1.31 | Avg E-: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 | Train Loss: 0.1527 | Val Loss: 0.1561 | Avg E+: 1.50 | Avg E-: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 | Train Loss: 0.1621 | Val Loss: 0.1664 | Avg E+: 1.39 | Avg E-: 1.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 | Train Loss: 0.1454 | Val Loss: 0.1359 | Avg E+: 1.99 | Avg E-: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 | Train Loss: 0.1429 | Val Loss: 0.1278 | Avg E+: 2.18 | Avg E-: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 | Train Loss: 0.1426 | Val Loss: 0.1431 | Avg E+: 1.08 | Avg E-: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 | Train Loss: 0.1499 | Val Loss: 0.1361 | Avg E+: 1.23 | Avg E-: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 | Train Loss: 0.1503 | Val Loss: 0.1442 | Avg E+: 1.95 | Avg E-: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 | Train Loss: 0.1325 | Val Loss: 0.1416 | Avg E+: 1.34 | Avg E-: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 | Train Loss: 0.1447 | Val Loss: 0.1462 | Avg E+: 1.39 | Avg E-: 1.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 | Train Loss: 0.1407 | Val Loss: 0.1484 | Avg E+: 1.28 | Avg E-: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 | Train Loss: 0.1541 | Val Loss: 0.1498 | Avg E+: 1.89 | Avg E-: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 | Train Loss: 0.1506 | Val Loss: 0.1540 | Avg E+: 1.42 | Avg E-: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 | Train Loss: 0.1614 | Val Loss: 0.1382 | Avg E+: 1.49 | Avg E-: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 16/16 [00:16<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 | Train Loss: 0.1340 | Val Loss: 0.1286 | Avg E+: 2.11 | Avg E-: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 16/16 [00:16<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 | Train Loss: 0.1367 | Val Loss: 0.1259 | Avg E+: 1.50 | Avg E-: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 16/16 [00:16<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 | Train Loss: 0.1351 | Val Loss: 0.1271 | Avg E+: 2.01 | Avg E-: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 16/16 [00:16<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 | Train Loss: 0.1382 | Val Loss: 0.1398 | Avg E+: 1.17 | Avg E-: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 16/16 [00:16<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 | Train Loss: 0.1378 | Val Loss: 0.1303 | Avg E+: 1.64 | Avg E-: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 | Train Loss: 0.1327 | Val Loss: 0.1161 | Avg E+: 2.62 | Avg E-: 2.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 | Train Loss: 0.1307 | Val Loss: 0.1261 | Avg E+: 1.19 | Avg E-: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 | Train Loss: 0.1285 | Val Loss: 0.1315 | Avg E+: 1.71 | Avg E-: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 16/16 [00:16<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 | Train Loss: 0.1234 | Val Loss: 0.1210 | Avg E+: 3.92 | Avg E-: 4.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 | Train Loss: 0.1201 | Val Loss: 0.1099 | Avg E+: 1.89 | Avg E-: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 | Train Loss: 0.1187 | Val Loss: 0.1253 | Avg E+: 1.72 | Avg E-: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 | Train Loss: 0.1322 | Val Loss: 0.1323 | Avg E+: 2.17 | Avg E-: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 | Train Loss: 0.1434 | Val Loss: 0.1479 | Avg E+: 1.62 | Avg E-: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 | Train Loss: 0.1352 | Val Loss: 0.1233 | Avg E+: 4.77 | Avg E-: 4.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 | Train Loss: 0.1223 | Val Loss: 0.1184 | Avg E+: 3.41 | Avg E-: 3.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 | Train Loss: 0.1290 | Val Loss: 0.1370 | Avg E+: 1.88 | Avg E-: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 | Train Loss: 0.1325 | Val Loss: 0.1323 | Avg E+: 2.11 | Avg E-: 2.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 | Train Loss: 0.1341 | Val Loss: 0.1431 | Avg E+: 3.05 | Avg E-: 2.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 | Train Loss: 0.1504 | Val Loss: 0.1346 | Avg E+: 2.28 | Avg E-: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 | Train Loss: 0.1366 | Val Loss: 0.1445 | Avg E+: 1.15 | Avg E-: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 | Train Loss: 0.1436 | Val Loss: 0.1424 | Avg E+: 1.23 | Avg E-: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 | Train Loss: 0.1543 | Val Loss: 0.1573 | Avg E+: 1.39 | Avg E-: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 | Train Loss: 0.1511 | Val Loss: 0.1293 | Avg E+: 1.13 | Avg E-: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 | Train Loss: 0.1322 | Val Loss: 0.1374 | Avg E+: 1.16 | Avg E-: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 | Train Loss: 0.1766 | Val Loss: 0.1883 | Avg E+: 2.70 | Avg E-: 2.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 | Train Loss: 0.1798 | Val Loss: 0.1778 | Avg E+: 1.27 | Avg E-: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 | Train Loss: 0.1764 | Val Loss: 0.1743 | Avg E+: 1.47 | Avg E-: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 | Train Loss: 0.1590 | Val Loss: 0.1518 | Avg E+: 2.80 | Avg E-: 2.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 | Train Loss: 0.1355 | Val Loss: 0.1181 | Avg E+: 2.58 | Avg E-: 2.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 | Train Loss: 0.1330 | Val Loss: 0.1197 | Avg E+: 1.50 | Avg E-: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 | Train Loss: 0.1158 | Val Loss: 0.1268 | Avg E+: 1.84 | Avg E-: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 | Train Loss: 0.1396 | Val Loss: 0.1215 | Avg E+: 3.68 | Avg E-: 4.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 | Train Loss: 0.1099 | Val Loss: 0.1094 | Avg E+: 3.36 | Avg E-: 3.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 | Train Loss: 0.1170 | Val Loss: 0.1168 | Avg E+: 2.37 | Avg E-: 2.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 | Train Loss: 0.1353 | Val Loss: 0.1346 | Avg E+: 4.25 | Avg E-: 4.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 | Train Loss: 0.1426 | Val Loss: 0.1523 | Avg E+: 3.85 | Avg E-: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 | Train Loss: 0.1596 | Val Loss: 0.1553 | Avg E+: 2.33 | Avg E-: 2.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 | Train Loss: 0.1503 | Val Loss: 0.1367 | Avg E+: 3.05 | Avg E-: 3.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 | Train Loss: 0.1422 | Val Loss: 0.1366 | Avg E+: 1.19 | Avg E-: 1.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 | Train Loss: 0.1355 | Val Loss: 0.1324 | Avg E+: 1.36 | Avg E-: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 | Train Loss: 0.1369 | Val Loss: 0.1342 | Avg E+: 3.07 | Avg E-: 3.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 16/16 [00:15<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 | Train Loss: 0.1393 | Val Loss: 0.1205 | Avg E+: 2.68 | Avg E-: 2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100:  25%|██▌       | 4/16 [00:03<00:11]"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c84e37f-b10d-4059-b25b-ac0235a62d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from matplotlib.transforms import Bbox\n",
    "from utils.jet_dataset import JetDataset\n",
    "from wnae import WNAE\n",
    "from model_config.model_registry import MODEL_REGISTRY\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba670220-05f8-49de-bc2d-19284b0c3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_mse(dataloader):\n",
    "    mses = []\n",
    "    for batch in dataloader:\n",
    "        x = batch[0].to(DEVICE, non_blocking=True)\n",
    "        recon_x = model.decoder(model.encoder(x))\n",
    "        per_sample_mse = torch.mean((x - recon_x) ** 2, dim=1)\n",
    "        mses.extend(per_sample_mse.detach().cpu().numpy())\n",
    "    return np.array(mses)\n",
    "\n",
    "def plot_checkpoint_energies(checkpoint, plot_dir=\"plots\"):\n",
    "    \"\"\"\n",
    "    Plot positive and negative energies per batch from a loaded checkpoint.\n",
    "\n",
    "    Args:\n",
    "        checkpoint: dictionary returned from torch.load(checkpoint_path)\n",
    "        plot_dir: directory to save plots\n",
    "    \"\"\"\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    \n",
    "    pos_energies = checkpoint.get(\"batch_pos_energies\", None)\n",
    "    neg_energies = checkpoint.get(\"batch_neg_energies\", None)\n",
    "    \n",
    "    if pos_energies is None or neg_energies is None:\n",
    "        print(\"[WARNING] Positive/Negative energies not found in checkpoint.\")\n",
    "        print(\"Checkpoint keys:\", checkpoint.keys())\n",
    "        return\n",
    "    \n",
    "    pos_energies = np.array(pos_energies)\n",
    "    neg_energies = np.array(neg_energies)\n",
    "    \n",
    "    # Plot energies per batch\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(pos_energies, label=\"Positive Energy\")\n",
    "    plt.plot(neg_energies, label=\"Negative Energy\")\n",
    "    plt.xlabel(\"Batch number\")\n",
    "    plt.ylabel(\"Energy\")\n",
    "    plt.legend(frameon=False)\n",
    "    #plt.grid(True)\n",
    "    plt.yscale('log')\n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(plot_dir, \"energies_per_batch.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.savefig(plot_path.replace(\".png\",\".pdf\"))\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"[INFO] Energy plot saved to: {plot_path}\")\n",
    "\n",
    "def load_dataset(file_path, key=\"Jets\", max_jets=10000, pt_cut=None):\n",
    "    tmp_ds = JetDataset(file_path, input_dim=INPUT_DIM, key=key, pt_cut=pt_cut)\n",
    "    # Sample random indices from the already cut dataset\n",
    "    if len(tmp_ds) > max_jets:\n",
    "        sampled = np.random.choice(tmp_ds.indices, size=max_jets, replace=False)\n",
    "        tmp_ds.indices = sampled\n",
    "    return tmp_ds\n",
    "\n",
    "def plot_eff_vs_pt(bkg_mses, sig_mses_dict, bkg_dataset, signal_loaders, wp=0.1, savedir=\"plots\"):\n",
    "    \"\"\"\n",
    "    Plot efficiency vs jet pT for a fixed working point defined by a background mistag rate.\n",
    "    \n",
    "    Args:\n",
    "        bkg_mses (np.ndarray): background MSE scores\n",
    "        sig_mses_dict (dict): {name: np.ndarray} of signal MSE scores\n",
    "        bkg_dataset (JetDataset): background dataset (provides pT)\n",
    "        signal_loaders (dict): {name: DataLoader} for signals (to get dataset pT)\n",
    "        wp (float): background mistag working point (e.g. 0.1 for 10%)\n",
    "        savedir (str): where to save plot\n",
    "    \"\"\"\n",
    "    # threshold from background: WP corresponds to (1 - wp) quantile\n",
    "    threshold = np.percentile(bkg_mses, 100 * (1 - wp))\n",
    "\n",
    "    bins_pt = np.linspace(150, 800, 50)  # adjust as needed\n",
    "    bin_centers = 0.5 * (bins_pt[:-1] + bins_pt[1:])\n",
    "\n",
    "    # background efficiency per pT bin\n",
    "    bkg_pts = bkg_dataset.get_pt()\n",
    "    bkg_eff_pt = []\n",
    "    for i in range(len(bins_pt) - 1):\n",
    "        mask = (bkg_pts >= bins_pt[i]) & (bkg_pts < bins_pt[i+1])\n",
    "        if np.sum(mask) > 0:\n",
    "            eff = np.mean(bkg_mses[mask] > threshold)\n",
    "        else:\n",
    "            eff = np.nan\n",
    "        bkg_eff_pt.append(eff)\n",
    "\n",
    "    # signal efficiencies per pT bin\n",
    "    sig_eff_pt_dict = {}\n",
    "    for name, sig_mses in sig_mses_dict.items():\n",
    "        sig_pts = signal_loaders[name].dataset.get_pt()\n",
    "        sig_eff = []\n",
    "        for i in range(len(bins_pt) - 1):\n",
    "            mask = (sig_pts >= bins_pt[i]) & (sig_pts < bins_pt[i+1])\n",
    "            if np.sum(mask) > 0:\n",
    "                eff = np.mean(sig_mses[mask] > threshold)\n",
    "            else:\n",
    "                eff = np.nan\n",
    "            sig_eff.append(eff)\n",
    "        sig_eff_pt_dict[name] = sig_eff\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.plot(bin_centers, bkg_eff_pt, label=f\"{BKG_NAME} mistag (WP={wp*100:.0f}%)\", linestyle=\"--\")\n",
    "    for name, eff in sig_eff_pt_dict.items():\n",
    "        ax.plot(bin_centers, eff, label=f\"{name}\")\n",
    "    ax.set_xlabel(\"Jet $p_T$ [GeV]\")\n",
    "    ax.set_ylabel(\"Efficiency\")\n",
    "    ax.set_ylim(0, 1.3)\n",
    "    ax.legend(ncol=2)\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    savefig = f\"{savedir}/plots/eff_vs_pt_wp_{wp}.png\"\n",
    "    plt.savefig(savefig, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"Saved {savefig}\")\n",
    "\n",
    "def plot_sample_vs_reconstruction(model, bkg_loader, savedir, device=torch.device(\"cpu\")):\n",
    "    \"\"\"\n",
    "    Plot one MCMC jet and one validation jet with original and reconstructed features.\n",
    "\n",
    "    Args:\n",
    "        model: trained WNAE model (should be in eval mode)\n",
    "        bkg_loader: DataLoader for background/validation jets\n",
    "        savedir: directory to save the plot\n",
    "    \"\"\"\n",
    "    # Get one validation jet\n",
    "    val_batch = next(iter(bkg_loader))\n",
    "    val_jet = val_batch[0][0:1].to(device)  # first jet in batch\n",
    "\n",
    "    val_energy, val_z, val_reco = model._WNAE__energy_with_samples(val_jet)\n",
    "\n",
    "    # Get one MCMC jet\n",
    "    if len(model.buffer.buffer) == 0:\n",
    "        raise ValueError(\"MCMC buffer is empty!\")\n",
    "    mcmc_jet = model.buffer.buffer[0].unsqueeze(0).to(device)  # first mcmc jet in batch\n",
    "    mcmc_energy, mcmc_z, mcmc_reco = model._WNAE__energy_with_samples(mcmc_jet)\n",
    "\n",
    "    n_features = val_jet.shape[1]\n",
    "    features = range(n_features)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    plt.plot(features, val_jet[0].cpu().numpy(), 'o-', color='C0', label='Val jet')\n",
    "    plt.plot(features, val_reco[0].detach().cpu().numpy(), 's--', color='C0', label='Val jet reco.')\n",
    "\n",
    "    plt.plot(features, mcmc_jet[0].cpu().numpy(), 'o-', color='C1', label='MCMC jet')\n",
    "    plt.plot(features, mcmc_reco[0].detach().cpu().numpy(), 's--', color='C1', label='MCMC jet reco.')\n",
    "\n",
    "    plt.xlabel(\"Feature index\")\n",
    "    plt.ylabel(\"Feature value\")\n",
    "\n",
    "    plt.text(0.95, 0.95, f\"Val energy: {val_energy.item():.1f}\", transform=plt.gca().transAxes,\n",
    "            horizontalalignment='right', verticalalignment='top', color='C0')\n",
    "    plt.text(0.95, 0.90, f\"MCMC energy: {mcmc_energy.item():.1f}\", transform=plt.gca().transAxes,\n",
    "            horizontalalignment='right', verticalalignment='top', color='C1')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    save_path = f\"{savedir}/sample_reconstruction.png\"\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    print(f\"Saved {save_path}\")\n",
    "\n",
    "    #Latent plot\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    n_latent = val_z.shape[1]\n",
    "    latent_idx = range(n_latent)\n",
    "\n",
    "    plt.plot(latent_idx, val_z[0].detach().cpu().numpy(), 'o-', color='C0', label='Val jet z')\n",
    "    plt.plot(latent_idx, mcmc_z[0].detach().cpu().numpy(), 'o-', color='C1', label='MCMC jet z')\n",
    "\n",
    "    plt.xlabel(\"Latent dimension index\")\n",
    "    plt.ylabel(\"Latent value\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    save_path_z = f\"{savedir}/sample_latent.png\"\n",
    "    plt.savefig(save_path_z)\n",
    "    plt.close()\n",
    "    print(f\"Saved {save_path_z}\")\n",
    "\n",
    "def plot_energy_distributions(model, bkg_loader, n_samples=10000, savedir=\"plots\", device=torch.device(\"cpu\")):\n",
    "    \"\"\"\n",
    "    Plot distributions of positive (data) and negative (MCMC) reconstruction energies\n",
    "    on separate subplots.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    E_pos_list = []\n",
    "    E_neg_list = []\n",
    "\n",
    "    # Collect positive (data) energies in batches\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in bkg_loader:\n",
    "            jets = batch[0].to(device)\n",
    "            energies, _, _ = model._WNAE__energy_with_samples(jets)  # batch processing\n",
    "            E_pos_list.extend(energies.cpu().numpy())\n",
    "            count += len(jets)\n",
    "            if count >= n_samples:\n",
    "                E_pos_list = E_pos_list[:n_samples]\n",
    "                break\n",
    "\n",
    "    # Collect negative (MCMC) energies\n",
    "    if len(model.buffer.buffer) == 0:\n",
    "        raise ValueError(\"MCMC buffer is empty!\")\n",
    "    mcmc_jets = torch.stack(model.buffer.buffer[:min(n_samples, len(model.buffer.buffer))]).to(device)\n",
    "    with torch.no_grad():\n",
    "        energies, _, _ = model._WNAE__energy_with_samples(mcmc_jets)\n",
    "        E_neg_list = energies.cpu().numpy()\n",
    "\n",
    "    # Compute 99th percentile for x-limits\n",
    "    x_pos_max = np.percentile(E_pos_list, 99)\n",
    "    x_neg_max = np.percentile(E_neg_list, 99)\n",
    "\n",
    "    # Plot distributions in two subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12,5), sharey=True)\n",
    "    axs[0].hist(E_pos_list, bins=np.linspace(0, x_pos_max, 50), histtype='step', color='C0')\n",
    "    axs[0].set_title(\"E+ (data)\")\n",
    "    axs[0].set_xlabel(\"Reconstruction energy\")\n",
    "    axs[0].set_ylabel(\"Counts\")\n",
    "    axs[0].set_xlim(0, x_pos_max)\n",
    "\n",
    "    axs[1].hist(E_neg_list, bins=np.linspace(0, x_neg_max, 50), histtype='step', color='C1')\n",
    "    axs[1].set_title(\"E- (MCMC)\")\n",
    "    axs[1].set_xlabel(\"Reconstruction energy\")\n",
    "    axs[1].set_xlim(0, x_neg_max)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "    save_path = f\"{savedir}/energy_distributions.png\"\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e254afb-cbe1-4d81-b66d-115e38c167a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading replay buffer from checkpoint\n",
      "Device is cuda\n",
      "Saved models/feat16_encoder32_deep_qcd_sinkhorn/plots/energy_distributions.png\n",
      "Saved models/feat16_encoder32_deep_qcd_sinkhorn/plots/sample_reconstruction.png\n",
      "Saved models/feat16_encoder32_deep_qcd_sinkhorn/plots/sample_latent.png\n",
      "[INFO] Energy plot saved to: models/feat16_encoder32_deep_qcd_sinkhorn/plots/energies_per_batch.png\n",
      "[INFO] Computing background mse...\n",
      "[INFO] Computing mse for signal: Top_bqq\n",
      "Saved models/feat16_encoder32_deep_qcd_sinkhorn/plots/summary.png\n",
      "Saved models/feat16_encoder32_deep_qcd_sinkhorn/plots/mse.png\n",
      "Saved models/feat16_encoder32_deep_qcd_sinkhorn/plots/roc.png\n",
      "Saved models/feat16_encoder32_deep_qcd_sinkhorn/plots/mass.png\n",
      "Saved models/feat16_encoder32_deep_qcd_sinkhorn/plots/pt.png\n",
      "Saved models/feat16_encoder32_deep_qcd_sinkhorn/plots/eff_vs_pt_wp_0.1.png\n",
      "[INFO] Evaluation complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_JETS = 20000\n",
    "PT_CUT = None\n",
    "BKG_NAME = model_config[\"process\"]\n",
    "CONFIG_PATH = \"data/dataset_config_small.json\"\n",
    "\n",
    "os.makedirs(f\"{SAVEDIR}/plots\", exist_ok=True)\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "bkg_path = config[BKG_NAME][\"path\"]\n",
    "bkg_dataset = load_dataset(bkg_path, max_jets=MAX_JETS,pt_cut=PT_CUT)\n",
    "bkg_loader = DataLoader(bkg_dataset, batch_size=BATCH_SIZE, sampler=SequentialSampler(bkg_dataset))\n",
    "\n",
    "signal_loaders = {}\n",
    "for name, sample in config.items():\n",
    "    if name==BKG_NAME:\n",
    "        continue\n",
    "    sig_dataset = load_dataset(sample[\"path\"], max_jets=MAX_JETS,pt_cut=PT_CUT)\n",
    "    signal_loaders[name] = DataLoader(sig_dataset, batch_size=BATCH_SIZE, sampler=SequentialSampler(sig_dataset))\n",
    "\n",
    "model = WNAE(encoder=model_config[\"encoder\"](),decoder=model_config[\"decoder\"](),**WNAE_PARAMS)\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE)[\"model_state_dict\"])\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "if \"buffer\" in checkpoint:\n",
    "    print(\"Loading replay buffer from checkpoint\")\n",
    "    if model.buffer.max_samples!=len(checkpoint[\"buffer\"]):\n",
    "        print(f'WARNING: stored buffer len ({len(checkpoint[\"buffer\"])}) different from declared buffer size {model.buffer.max_samples}')\n",
    "        model.buffer.buffer = checkpoint[\"buffer\"][:model.buffer.max_samples]\n",
    "    else:\n",
    "        model.buffer.buffer = checkpoint[\"buffer\"]\n",
    "print(f\"Device is {DEVICE}\")\n",
    "plot_energy_distributions(model, bkg_loader, savedir=f\"{SAVEDIR}/plots\", device=DEVICE)\n",
    "plot_sample_vs_reconstruction(model, bkg_loader, savedir=f\"{SAVEDIR}/plots\", device=DEVICE)\n",
    "plot_checkpoint_energies(checkpoint, plot_dir=f\"{SAVEDIR}/plots/\")\n",
    "\n",
    "print(\"[INFO] Computing background mse...\")\n",
    "bkg_mses = compute_mse(bkg_loader)\n",
    "\n",
    "sig_mses_dict = {}\n",
    "for name, loader in signal_loaders.items():\n",
    "    print(f\"[INFO] Computing mse for signal: {name}\")\n",
    "    sig_mses_dict[name] = compute_mse(loader)\n",
    "# --- Combined figure: mse, ROC, mass, pt ---\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# --- 1) Mse distributions ---\n",
    "ax_mse = axes[0, 0]\n",
    "\n",
    "all_mses = np.concatenate([bkg_mses] + list(sig_mses_dict.values()))\n",
    "_, x_max = np.percentile(all_mses, [0, 99.])\n",
    "\n",
    "\n",
    "bins_mse = np.linspace(0, x_max, 101)\n",
    "ax_mse.hist(bkg_mses, bins=bins_mse, histtype='step', label=BKG_NAME, density=True)\n",
    "for name, mses in sig_mses_dict.items():\n",
    "    ax_mse.hist(mses, bins=bins_mse, histtype='step', label=name, density=True)\n",
    "ax_mse.set_xlabel(\"Reconstruction MSE\")\n",
    "ax_mse.set_ylabel(\"Density\")\n",
    "ax_mse.set_xlim([0, x_max])\n",
    "ax_mse.legend()\n",
    "\n",
    "# --- 2) ROC curves ---\n",
    "ax_roc = axes[0, 1]\n",
    "all_labels = np.zeros_like(bkg_mses)\n",
    "for name, sig_mses in sig_mses_dict.items():\n",
    "    labels = np.concatenate([all_labels, np.ones_like(sig_mses)])\n",
    "    scores = np.concatenate([bkg_mses, sig_mses])\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax_roc.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.3f})\")\n",
    "ax_roc.plot([0, 1], [0, 1], color=\"navy\", lw=1, linestyle=\"--\")\n",
    "ax_roc.set_xlabel(\"Background mistag rate\")\n",
    "ax_roc.set_ylabel(\"Signal efficiency\")\n",
    "ax_roc.legend(loc=\"lower right\")\n",
    "ax_roc.grid(True, alpha=0.3)\n",
    "\n",
    "# --- 3) Jet mass distributions ---\n",
    "ax_mass = axes[1, 0]\n",
    "bins_mass = np.linspace(0, 200, 101)\n",
    "ax_mass.hist(bkg_dataset.get_mass(), bins=bins_mass, histtype='step', density=True, label=BKG_NAME)\n",
    "for name, loader in signal_loaders.items():\n",
    "    sig_ds = loader.dataset\n",
    "    ax_mass.hist(sig_ds.get_mass(), bins=bins_mass, histtype='step', density=True, label=name)\n",
    "ax_mass.set_xlabel(\"Jet mass [GeV]\")\n",
    "ax_mass.set_ylabel(\"Density\")\n",
    "ax_mass.legend()\n",
    "\n",
    "# --- 4) Jet pt distributions ---\n",
    "ax_pt = axes[1, 1]\n",
    "bins_pt = np.linspace(150, 800, 65)\n",
    "ax_pt.hist(bkg_dataset.get_pt(), bins=bins_pt, histtype='step', density=True, label=BKG_NAME)\n",
    "for name, loader in signal_loaders.items():\n",
    "    sig_ds = loader.dataset\n",
    "    ax_pt.hist(sig_ds.get_pt(), bins=bins_pt, histtype='step', density=True, label=name)\n",
    "ax_pt.set_xlabel(\"Jet $p_T$ [GeV]\")\n",
    "ax_pt.set_ylabel(\"Density\")\n",
    "ax_pt.set_ylim(1e-4, 3*1e-2)\n",
    "ax_pt.set_yscale(\"log\")\n",
    "ax_pt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig = f\"{SAVEDIR}/plots/summary.png\"\n",
    "plt.savefig(savefig, dpi=200)\n",
    "plt.close()\n",
    "print(f\"Saved {savefig}\")\n",
    "\n",
    "\n",
    "# --- Save each subplot individually ---\n",
    "#Thank you SO: https://stackoverflow.com/questions/4325733/save-a-subplot-in-matplotlib\n",
    "individual_plots = {\n",
    "    \"mse\": ax_mse,\n",
    "    \"roc\": ax_roc,\n",
    "    \"mass\": ax_mass,\n",
    "    \"pt\": ax_pt,\n",
    "}\n",
    "\n",
    "expand_left_frac = 0.12 \n",
    "expand_right_frac = 0.05\n",
    "expand_bottom_frac = 0.11\n",
    "expand_top_frac = 0.01\n",
    "\n",
    "\n",
    "for name, ax in individual_plots.items():\n",
    "    fig = ax.figure\n",
    "    extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "    # Slightly expand to avoid clipping labels, legends, ticks\n",
    "    width = extent.width\n",
    "    height = extent.height\n",
    "    \n",
    "\n",
    "    new_extent = Bbox.from_bounds(\n",
    "        extent.x0 - width * expand_left_frac,\n",
    "        extent.y0 - height * expand_bottom_frac,\n",
    "        width + width * (expand_left_frac + expand_right_frac),\n",
    "        height + height * (expand_bottom_frac + expand_top_frac)\n",
    "    )\n",
    "    # Save\n",
    "    savefig = f\"{SAVEDIR}/plots/{name}.png\"\n",
    "    fig.savefig(savefig, dpi=200, bbox_inches=new_extent)\n",
    "    print(f\"Saved {savefig}\")\n",
    "\n",
    "\n",
    "plot_eff_vs_pt(bkg_mses, sig_mses_dict, bkg_dataset, signal_loaders, wp=0.1, savedir=SAVEDIR)\n",
    "print(\"[INFO] Evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8242e572-a294-4087-b978-7982eabcdce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-wnae_env]",
   "language": "python",
   "name": "conda-env-.conda-wnae_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
